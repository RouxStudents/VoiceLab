# HumanitarianCorpus

Sophisticated natural language processing models like BERT are pre-trained using large corpora such as **Wikipedia** and **BooksCorpus**. This project aims to develop a custom domain-specific corpus for training models how to process humanitarian data and queries posed by humanitarian actors.

The **HumanitarianCorpus** will primarily aggregate text from:

* IATI
* Humanitarian Data Exchange
* ReliefWeb
* Books
* Publications
* Organization websites
